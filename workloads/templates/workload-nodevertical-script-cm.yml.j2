apiVersion: v1
kind: ConfigMap
metadata:
  name: scale-ci-workload-script
data:
  run.sh: |
    #!/bin/sh
    set -eo pipefail
    workload_log() { echo "$(date -u) $@" >&2; }
    export -f workload_log
    workload_log "Configuring pbench for NodeVertical"
    mkdir -p /var/lib/pbench-agent/tools-default/
    echo "${USER_NAME:-default}:x:$(id -u):0:${USER_NAME:-default} user:${HOME}:/sbin/nologin" >> /etc/passwd
    source /opt/pbench-agent/profile
    if [ "${ENABLE_PBENCH_AGENTS}" = true ]; then
      # clear tools/remotes to make sure there are no invalid remotes
      set +eo pipefail
      pbench-clear-tools
      set -eo pipefail
      echo "" > /var/lib/pbench-agent/tools-default/disk
      echo "" > /var/lib/pbench-agent/tools-default/iostat
      echo "workload" > /var/lib/pbench-agent/tools-default/label
      echo "" > /var/lib/pbench-agent/tools-default/mpstat
      echo "" > /var/lib/pbench-agent/tools-default/oc
      echo "" > /var/lib/pbench-agent/tools-default/perf
      echo "" > /var/lib/pbench-agent/tools-default/pidstat
      echo "" > /var/lib/pbench-agent/tools-default/sar
      master_nodes=`oc get nodes -l pbench_agent=true,node-role.kubernetes.io/master= --no-headers | awk '{print $1}'`
      for node in $master_nodes; do
        echo "master" > /var/lib/pbench-agent/tools-default/remote@$node
      done
      infra_nodes=`oc get nodes -l pbench_agent=true,node-role.kubernetes.io/infra= --no-headers | awk '{print $1}'`
      for node in $infra_nodes; do
        echo "infra" > /var/lib/pbench-agent/tools-default/remote@$node
      done
      worker_nodes=`oc get nodes -l pbench_agent=true,node-role.kubernetes.io/worker= --no-headers | awk '{print $1}'`
      for node in $worker_nodes; do
        echo "worker" > /var/lib/pbench-agent/tools-default/remote@$node
      done
    fi
    workload_log "Done configuring pbench NodeVertical"

    workload_log "Configuring NodeVertical test"
    envsubst < /root/workload/nodevertical.yaml.template > /tmp/nodevertical.yaml
    envsubst < /root/workload/nodevert-pod-labeled.yaml.template > /tmp/nodevert-pod-labeled.yaml
    workload_log "Done configuring NodeVertical test"

    workload_log "Running NodeVertical workload"
    if [ "${PBENCH_INSTRUMENTATION}" = "true" ]; then
      pbench-user-benchmark -- sh /root/workload/workload.sh
      result_dir="/var/lib/pbench-agent/$(ls -t /var/lib/pbench-agent/ | grep "pbench-user" | head -1)"/1/sample1
      if [ "${ENABLE_PBENCH_COPY}" = "true" ]; then
        pbench-copy-results --prefix ${NODEVERTICAL_TEST_PREFIX}
      fi
    else
      sh /root/workload/workload.sh
      result_dir=/tmp
    fi
    workload_log "Completed NodeVertical workload run"

    workload_log "Checking Test Results"
    workload_log "Checking Cluster Loader Exit Code"
    if [ "$(jq '.exit_code==0' ${result_dir}/exit.json)" = "false" ]; then
      workload_log "Cluster Loader Failure"
      workload_log "Test Analysis: Failed due to Cluster Loader failure"
      exit 1
    fi
    workload_log "Comparing NodeVertical duration to expected duration"
    workload_log "NodeVertical Duration: $(jq '.duration' ${result_dir}/exit.json)"
    if [ "$(jq '.duration>'${EXPECTED_NODEVERTICAL_DURATION}'' ${result_dir}/exit.json)" = "true" ]; then
      workload_log "EXPECTED_NODEVERTICAL_DURATION (${EXPECTED_NODEVERTICAL_DURATION}) exceeded ($(jq '.duration' ${result_dir}/exit.json))"
      workload_log "Test Analysis: Failed due to NodeVertical run duration taking more time than expected duration"
      exit 1
    fi
    workload_log "Cluster Loader Metrics: $(cat ${result_dir}/clusterloader.json | jq '.')"
    # TODO: Check pbench-agent collected metrics for Pass/Fail
    # TODO: Check prometheus collected metrics for Pass/Fail
    workload_log "Test Analysis: Passed"
  workload.sh: |
    #!/bin/sh
    set -o pipefail

    result_dir=/tmp
    if [ "${PBENCH_INSTRUMENTATION}" = "true" ]; then
      result_dir=${benchmark_results_dir}
    fi
    start_time=$(date +%s)
    if [[ "${AZURE_AUTH}" == "true" ]]; then
      export AZURE_AUTH_LOCATION=/tmp/azure_auth
    fi
    export cluster_name={{ snafu_cluster_name }}
    export test_user={{ snafu_user }}
    export es={{ snafu_es_host }}
    export es_port={{ snafu_es_port }}
    export es_index={{ snafu_es_index_prefix }}
    VIPERCONFIG=/tmp/nodevertical.yaml python3 /tmp/snafu/run_snafu.py -t cl scale-ci --cl-output True --dir "${result_dir}" -p openshift-tests | tee "${result_dir}/clusterloader.txt"
    exit_code=$?
    end_time=$(date +%s)
    duration=$((end_time-start_time))

    workload_log "Writing Cluster Loader Exit Code"
    jq -n '. | ."exit_code"='${exit_code}' | ."duration"='${duration}'' > "${result_dir}/exit.json"
    workload_log "Writing Cluster Loader Metrics to clusterloader.json"
    grep "cluster_loader_marker" ${result_dir}/clusterloader.txt > "${result_dir}/clusterloader.json"

    workload_log "Finished workload script"
  nodevertical.yaml.template: |
    provider: local
    ClusterLoader:
      cleanup: ${NODEVERTICAL_CLEANUP}
      projects:
        - num: 1
          basename: ${NODEVERTICAL_BASENAME}
          tuning: default
          ifexists: delete
          nodeselector: "node-role.kubernetes.io/worker="
          pods:
            - num: ${TOTAL_POD_COUNT}
              basename: nodevert
              file: nodevert-pod-labeled.yaml
      tuningsets:
        - name: default
          pods:
            stepping:
              stepsize: ${NODEVERTICAL_STEPSIZE}
              pause: ${NODEVERTICAL_PAUSE}
              timeout: ${NODEVERTICAL_TS_TIMEOUT}
            ratelimit:
              delay: 0
  nodevert-pod-labeled.yaml.template: |
    ---
    kind: Pod
    apiVersion: v1
    metadata:
      name: nodevert
      labels:
        name: nodevert
    spec:
      containers:
      - name: nodevert
        image: ${NODEVERTICAL_POD_IMAGE}
        ports:
        - containerPort: 8080
          protocol: TCP
        imagePullPolicy: IfNotPresent
        securityContext:
          privileged: false
      nodeSelector:
        nodevertical: 'true'
